{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"provenance":[],"collapsed_sections":["479fe902","358c8b67","525d5d4a","f37d85d1","4cb3c5d4","fe5ad30b","6ae61424"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"cells":[{"cell_type":"code","source":["!pip install import-ipynb\n","import import_ipynb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Pc50qsfJHfa","executionInfo":{"status":"ok","timestamp":1666006225982,"user_tz":-480,"elapsed":3856,"user":{"displayName":"Mansi Agarwal","userId":"01259360581954223859"}},"outputId":"32d029a9-ca4e-430b-a0b4-7dce7b90894d"},"id":"4Pc50qsfJHfa","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting import-ipynb\n","  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from import-ipynb) (7.9.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from import-ipynb) (5.7.0)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 33.4 MB/s \n","\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (2.6.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (5.1.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (4.4.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (0.2.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (57.4.0)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (4.8.0)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (2.0.10)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->IPython->import-ipynb) (0.8.3)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import-ipynb) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import-ipynb) (0.2.5)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.3.3)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (2.16.2)\n","Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (5.0.0)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.11.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->import-ipynb) (3.9.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->import-ipynb) (4.1.1)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.18.1)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (22.1.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (5.10.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->import-ipynb) (0.7.0)\n","Installing collected packages: jedi, import-ipynb\n","Successfully installed import-ipynb-0.1.4 jedi-0.18.1\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Sd9K-eL1FU9J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666006245853,"user_tz":-480,"elapsed":19877,"user":{"displayName":"Mansi Agarwal","userId":"01259360581954223859"}},"outputId":"33ae57f4-2055-4580-fe80-d5d95785f081"},"id":"Sd9K-eL1FU9J","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pwd\n","%cd /content/drive/My Drive/CS5344 Big Data/Big data GP/\n","!pwd\n","\n","# !git init Multimodal Fake News Detection Reddit\n","%cd Multimodal Fake News Detection Reddit/\n","!ls -a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HmI-CWERLf9G","executionInfo":{"status":"ok","timestamp":1666006247283,"user_tz":-480,"elapsed":1437,"user":{"displayName":"Mansi Agarwal","userId":"01259360581954223859"}},"outputId":"bc422a77-ccfd-4067-d6fe-8b60518ee96f"},"id":"HmI-CWERLf9G","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/drive/.shortcut-targets-by-id/1-4dUCmoeQauWn6cyjjA06mec_yTcKmmn/CS5344 Big Data/Big data GP\n","/content/drive/.shortcut-targets-by-id/1-4dUCmoeQauWn6cyjjA06mec_yTcKmmn/CS5344 Big Data/Big data GP\n","/content/drive/.shortcut-targets-by-id/1-4dUCmoeQauWn6cyjjA06mec_yTcKmmn/CS5344 Big Data/Big data GP/Multimodal Fake News Detection Reddit\n","'CNN 6-way.ipynb'   .git   github_colab_token.py   .gitignore   __pycache__\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":92},"id":"GWdpsUZ-SNqN","executionInfo":{"status":"ok","timestamp":1666003735906,"user_tz":-480,"elapsed":25047,"user":{"displayName":"Mansi Agarwal","userId":"01259360581954223859"}},"outputId":"7d4ed2ec-0d56-4569-a598-a0a150dec510"},"id":"GWdpsUZ-SNqN","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-fc086f57-9608-4a2a-a8d4-d949ff205177\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-fc086f57-9608-4a2a-a8d4-d949ff205177\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving github_colab_token.py to github_colab_token (1).py\n","User uploaded file \"github_colab_token.py\" with length 279 bytes\n"]}]},{"cell_type":"code","source":["# import github_colab_token\n","from github_colab_token import username, git_token\n","repository='Multimodal-Fake-News-Detection-Reddit'\n","\n","!git remote -v\n","!git remote add origin https://{git_token}@github.com/{username}/{repository}.git\n","!git remote -v\n","!git config --global user.email \"agarwalmansi2911@gmail.com\"\n","!git config --global user.name \"Mansi Agarwal\"\n","# !git commit -am \"Updated tokens\"\n","!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UK8__6xMH4EI","executionInfo":{"status":"ok","timestamp":1666006386737,"user_tz":-480,"elapsed":1553,"user":{"displayName":"Mansi Agarwal","userId":"01259360581954223859"}},"outputId":"ffc2846b-1919-4d34-a859-679ba4403019"},"id":"UK8__6xMH4EI","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["origin\thttps://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@github.com/contactmansi/Multimodal-Fake-News-Detection-Reddit.git (fetch)\n","origin\thttps://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@github.com/contactmansi/Multimodal-Fake-News-Detection-Reddit.git (push)\n","fatal: remote origin already exists.\n","origin\thttps://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@github.com/contactmansi/Multimodal-Fake-News-Detection-Reddit.git (fetch)\n","origin\thttps://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@github.com/contactmansi/Multimodal-Fake-News-Detection-Reddit.git (push)\n","On branch master\n","Your branch is ahead of 'origin/master' by 4 commits.\n","  (use \"git push\" to publish your local commits)\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   CNN 6-way.ipynb\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"code","source":["!git status\n","!git add .\n","!git commit -am \"Updated tokens\"\n","!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s9RTW02VkQNG","executionInfo":{"status":"ok","timestamp":1666006275834,"user_tz":-480,"elapsed":3347,"user":{"displayName":"Mansi Agarwal","userId":"01259360581954223859"}},"outputId":"9d8061e5-4079-4a32-ca69-3fad06dd368e"},"id":"s9RTW02VkQNG","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch master\n","Your branch is ahead of 'origin/master' by 3 commits.\n","  (use \"git push\" to publish your local commits)\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   CNN 6-way.ipynb\u001b[m\n","\t\u001b[31mmodified:   github_colab_token.py\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n","[master f502441] Updated tokens\n"," 2 files changed, 2 insertions(+), 2 deletions(-)\n","On branch master\n","Your branch is ahead of 'origin/master' by 4 commits.\n","  (use \"git push\" to publish your local commits)\n","\n","nothing to commit, working tree clean\n"]}]},{"cell_type":"code","source":["# !git push https://contactmansi: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@github.com/contactmansi/Multimodal-Fake-News-Detection-Reddit.git\n","!git push origin master"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PGr_Fw-UDtE9","executionInfo":{"status":"ok","timestamp":1666006283513,"user_tz":-480,"elapsed":561,"user":{"displayName":"Mansi Agarwal","userId":"01259360581954223859"}},"outputId":"f75b266c-732a-421d-94d0-5a3b4e616d60"},"id":"PGr_Fw-UDtE9","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: could not read Password for 'https://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@github.com': No such device or address\n"]}]},{"cell_type":"markdown","metadata":{"id":"479fe902"},"source":["# Multimodal Fake News Detection CNN 6-way\n","\n","We start by importing the libraries."],"id":"479fe902"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33bc9936","outputId":"9c304cc4-674d-4de9-ab3b-05380b267d7b","executionInfo":{"status":"ok","timestamp":1665554308190,"user_tz":-480,"elapsed":16488,"user":{"displayName":"Mansi Agarwal","userId":"01259360581954223859"}}},"source":["# Import libraries\n","import numpy as np\n","import time\n","import os\n","import matplotlib\n","import matplotlib.image as mpimg\n","import pandas as pd\n","from torch import optim\n","import matplotlib.pyplot as plt\n","from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","import re\n","\n","import spacy\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk import word_tokenize\n","from nltk.stem.porter import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, Dataset\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import cv2 \n","import multiprocessing as mp\n","# import FunctionsTFM \n","import imp\n","import threading\n","\n","\n","%matplotlib inline"],"id":"33bc9936","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jeGlZfzKab2Y","outputId":"378734c1-6bba-4e86-f91a-d2e69d6d195a","executionInfo":{"status":"ok","timestamp":1665554615848,"user_tz":-480,"elapsed":307663,"user":{"displayName":"Mansi Agarwal","userId":"01259360581954223859"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"jeGlZfzKab2Y","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"5df1b35a"},"source":["We also import the data."],"id":"5df1b35a"},{"cell_type":"code","metadata":{"id":"a27cd18f"},"source":["# Train data \n","traindata_all = pd.read_csv('/content/drive/MyDrive/CS5344/Dataset/Fakeddit datasetv2.0/all_samples/all_train.tsv', sep='\\t')\n","# Validation data \n","validata_all = pd.read_csv('/content/drive/MyDrive/CS5344/Dataset/Fakeddit datasetv2.0/all_samples/all_validate.tsv', sep='\\t')\n","# Test data \n","testdata_all = pd.read_csv('/content/drive/MyDrive/CS5344/Dataset/Fakeddit datasetv2.0/all_samples/all_test_public.tsv', sep='\\t')"],"id":"a27cd18f","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"56eed200"},"source":["We select a subset of the dataframe with no missing values in the 'clean_title' column."],"id":"56eed200"},{"cell_type":"code","metadata":{"id":"e3574cfc"},"source":["# Train data with no missing values\n","train_data = traindata_all[traindata_all['clean_title'].notnull().to_numpy()]\n","# Validation data with no missing values\n","valid_data = validata_all[validata_all['clean_title'].notnull().to_numpy()]\n","# Test data with no missing values\n","test_data = testdata_all[testdata_all['clean_title'].notnull().to_numpy()]"],"id":"e3574cfc","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5d62f80a"},"source":["And we separate the datasets into the texts and the labels"],"id":"5d62f80a"},{"cell_type":"code","metadata":{"id":"9149859d"},"source":["## Train data\n","train_news = list(train_data['clean_title'])\n","train_labels = list(train_data['6_way_label'])\n","## Valid data\n","valid_news = list(valid_data['clean_title'])\n","valid_labels = list(valid_data['6_way_label'])\n","## Test data\n","test_news = list(test_data['clean_title'])\n","test_labels = list(test_data['6_way_label'])"],"id":"9149859d","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a444c553"},"source":["## Preprocessing\n","\n","We define a function to preprocess the data. We remove punctuations and numbers and also multiple spaces."],"id":"a444c553"},{"cell_type":"code","metadata":{"id":"2571f879"},"source":["def preprocess_text(sen):\n","    # Remove punctuations and numbers\n","    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n","\n","    # Removing multiple spaces\n","    sentence = re.sub(r'\\s+', ' ', sentence)\n","\n","    return sentence"],"id":"2571f879","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ab17f801"},"source":["# Remove puntuations and numbers and multiple spaces\n","\n","train_news_clean_1 = []\n","valid_news_clean_1 = []\n","test_news_clean_1 = []\n","# Train\n","for new in train_news:\n","    train_news_clean_1.append(preprocess_text(new))\n","# Validation\n","for new in valid_news:\n","    valid_news_clean_1.append(preprocess_text(new))\n","# Test\n","for new in test_news:\n","    test_news_clean_1.append(preprocess_text(new))"],"id":"ab17f801","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3f1903e8"},"source":["Now  we remove stop words and perform lemmatization. We define the function to do that."],"id":"3f1903e8"},{"cell_type":"code","metadata":{"id":"79086ac8"},"source":["# Initialize  lemmatizer and  stop_words\n","\n","lemmatizer = WordNetLemmatizer()\n","stop_words = set(stopwords.words('english')) \n","\n","# Function to remove stopwords and perform lemmatization\n","def remove_stopwords_lem(text):\n","    text = word_tokenize(text)\n","    # Remove stopwords\n","    text = [word for word in text if word not in stop_words]\n","    # Lematization\n","    lemmatized_text = []\n","    for word in text:\n","        word1 = lemmatizer.lemmatize(word, pos = \"n\")\n","        word2 = lemmatizer.lemmatize(word1, pos = \"v\")\n","        word3 = lemmatizer.lemmatize(word2, pos = (\"a\"))\n","        lemmatized_text.append(word3)\n","        \n","    text_done = ' '.join(lemmatized_text)\n","    return text_done"],"id":"79086ac8","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"16ef9e76"},"source":["And now perform stop-words removal and lemmatization."],"id":"16ef9e76"},{"cell_type":"code","metadata":{"id":"e81981a6"},"source":["# Stop-words removal and lemmatization\n","train_stwrd_lem = []\n","valid_stwrd_lem = []\n","test_stwrd_lem = []\n","\n","# Train\n","for new in train_news_clean_1:\n","    train_stwrd_lem.append(remove_stopwords_lem(new))\n","# Validation\n","for new in valid_news_clean_1:\n","    valid_stwrd_lem.append(remove_stopwords_lem(new))\n","# Test\n","for new in test_news_clean_1:\n","    test_stwrd_lem.append(remove_stopwords_lem(new))"],"id":"e81981a6","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5eca516c"},"source":["We train a tokenizer using all the documents and we use the learned vocabulary in order to transform texts into sequences of ID's."],"id":"5eca516c"},{"cell_type":"code","metadata":{"id":"21ed842a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665554786817,"user_tz":-480,"elapsed":18858,"user":{"displayName":"Mansi Agarwal","userId":"01259360581954223859"}},"outputId":"515b59dd-3129-42f1-efdb-e6a1eaf31d97"},"source":["news_all = train_stwrd_lem + valid_stwrd_lem + test_stwrd_lem\n","print(len(news_all))\n","tokenizer = Tokenizer(num_words = 128022) # Why this number? -- look up paper\n","tokenizer.fit_on_texts(news_all)\n","\n","# Tokenize news\n","\n","# Train\n","train_tokenized = tokenizer.texts_to_sequences(train_stwrd_lem)\n","# Validation\n","valid_tokenized = tokenizer.texts_to_sequences(valid_stwrd_lem)\n","# Test\n","test_tokenized = tokenizer.texts_to_sequences(test_stwrd_lem)"],"id":"21ed842a","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["971806\n"]}]},{"cell_type":"markdown","metadata":{"id":"cS84b4HnhlEo"},"source":["Obtain the vocabulary length"],"id":"cS84b4HnhlEo"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UPFdr3kQhp_B","outputId":"98c46f9c-3ded-455b-a0ac-d1338e80dac6","executionInfo":{"status":"ok","timestamp":1665554786817,"user_tz":-480,"elapsed":20,"user":{"displayName":"Mansi Agarwal","userId":"01259360581954223859"}}},"source":["vocab_size = len(tokenizer.word_index)\n","print(\"Vocabulary length: \", vocab_size)"],"id":"UPFdr3kQhp_B","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary length:  142720\n"]}]},{"cell_type":"markdown","metadata":{"id":"259c25be"},"source":["Now we pad the sequences of numbers generated by the tokenizer. But firstly we check how many sequences are shorter than a given length. We start by defining a function that counts the length of each sequence."],"id":"259c25be"},{"cell_type":"code","metadata":{"id":"a4f507be"},"source":["# Function to count the lenght of each sequence\n","def length_squences(data):\n","    lengths = []\n","    for i in range(len(data)):\n","        lengths.append(len(data[i]))\n","    return lengths"],"id":"a4f507be","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1df362bd"},"source":["Now we count the lenghts of all the sequences in the training, validation and test set and we check what % of sequences in the train, validation and test sets are smaller than a given length when they are tokenized."],"id":"1df362bd"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8k_WvwCqkW5K","outputId":"c9d18647-3d7a-44e4-ede8-e2577261ec8e","executionInfo":{"status":"ok","timestamp":1665554793646,"user_tz":-480,"elapsed":6843,"user":{"displayName":"Mansi Agarwal","userId":"01259360581954223859"}}},"source":["length = [10, 15, 20, 25]\n","\n","# Train set\n","lengths_train = np.array(length_squences(train_tokenized))\n","perc_length_train = []\n","for lgth in length:\n","   perc_length_train.append( sum(lengths_train < lgth)/len(lengths_train)*100)\n","print(\"Percentages (train):\", perc_length_train)\n","\n","# Validation set \n","lengths_valid = np.array(length_squences(valid_tokenized))\n","perc_length_valid = []\n","for lgth in length:\n","   perc_length_valid.append( sum(lengths_valid < lgth)/len(lengths_valid)*100)\n","print(\"Percentages (validation):\", perc_length_valid)\n","\n","# Test set\n","lengths_test = np.array(length_squences(test_tokenized))\n","perc_length_test = []\n","for lgth in length:\n","   perc_length_test.append( sum(lengths_test < lgth)/len(lengths_test)*100)\n","print(\"Percentages (test):\", perc_length_test)"],"id":"8k_WvwCqkW5K","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Percentages (train): [89.48079756947342, 98.23079289825844, 99.43023633856468, 99.79446654102136]\n","Percentages (validation): [89.75702659222107, 98.27174221633386, 99.46768240749503, 99.8024510267815]\n","Percentages (test): [89.74680697434925, 98.31678128810029, 99.46260105822611, 99.80824090623928]\n"]}]},{"cell_type":"markdown","metadata":{"id":"JgG1riOjlxNb"},"source":["We plot the results."],"id":"JgG1riOjlxNb"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"UoF5Nrlll08D","outputId":"0dff8970-df50-47b6-8471-a3a4677e79ec","executionInfo":{"status":"ok","timestamp":1665554794450,"user_tz":-480,"elapsed":821,"user":{"displayName":"Mansi Agarwal","userId":"01259360581954223859"}}},"source":["import matplotlib.pyplot as plt\n","# create dataset\n","bars = list(sum(zip(perc_length_train, perc_length_valid, perc_length_test), ()))\n","labels = ['< 10', '< 15', '< 20', '< 25']\n","\n","x_pos_bars = [1, 2, 3, 6, 7, 8, 11, 12, 13, 16, 17, 18]\n","x_pos_labels = [2, 7, 12, 17]\n","\n","# Colors and mapping to values\n","colors = ['g', 'b', 'r']\n","colors_values = {'Train':'g', 'Validation':'b', 'Test': 'r'}    \n","\n","labels2 = list(colors_values.keys())\n","handles = [plt.Rectangle((0,0),1,1, color=colors_values[label]) for label in labels2]\n","# Make the plot\n","plt.bar(x_pos_bars, bars,color = colors, label = colors_values)\n","\n","# Create names on the x-axis\n","plt.xticks(x_pos_labels, labels)\n","plt.legend(handles, labels2)\n","plt.ylim([0, 130])\n","#plt.xlabel('Metrics')\n","plt.ylabel('Percentage (%)')\n","plt.title('% of texts smaller than a given length')\n","plt.show()"],"id":"UoF5Nrlll08D","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"655078ba"},"source":["As we can see almost all news are smaller than **15** in length when tokenized so choosing this lenght to pad/truncate the tokenized news will not eliminate any information from the news in almost any case."],"id":"655078ba"},{"cell_type":"code","metadata":{"id":"999ccdba"},"source":["# Pad/truncate the tokenized news\n","\n","# Train\n","train_tokenized_pad = pad_sequences(train_tokenized, maxlen = 15, truncating = 'pre', padding = 'pre')\n","# Validation\n","valid_tokenized_pad = pad_sequences(valid_tokenized, maxlen = 15, truncating = 'pre', padding = 'pre')\n","# Test\n","test_tokenized_pad = pad_sequences(test_tokenized, maxlen = 15, truncating = 'pre', padding = 'pre')"],"id":"999ccdba","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now let's setup the GPU environment. The colab provides a free GPU to use. Do as follows:\n","\n","Runtime -> Change Runtime Type -> select GPU in Hardware accelerator\n","Click connect on the top-right\n","After connecting to one GPU, you can check its status using nvidia-smi comman"],"metadata":{"id":"m_e8qDaO1kf5"},"id":"m_e8qDaO1kf5"},{"cell_type":"code","source":["!nvidia-smi\n","torch.cuda.is_available()"],"metadata":{"id":"nhKURGAb1f6_"},"id":"nhKURGAb1f6_","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3c40705c"},"source":["In order to use the data with torch we have to transform the arrays into dataloader objects but first they need to be transformed into tensors."],"id":"3c40705c"},{"cell_type":"code","metadata":{"id":"0cdbc432"},"source":["# Transform data arrays into tensors\n","\n","# Train\n","train_tensor = torch.Tensor(train_tokenized_pad).int()\n","# Validation\n","valid_tensor = torch.Tensor(valid_tokenized_pad).int()\n","# Test\n","test_tensor =  torch.Tensor(test_tokenized_pad).int()\n","\n","# Tranform tensors into data loader objects\n","\n","# Train\n","train_set = TensorDataset(train_tensor, torch.Tensor(np.array(train_labels)))\n","trainloader = DataLoader(train_set, batch_size=64)\n","# Validation\n","valid_set = TensorDataset(valid_tensor, torch.Tensor(np.array(valid_labels)))\n","validloader = DataLoader(valid_set, batch_size=64)\n","# Test\n","test_set = TensorDataset(test_tensor, torch.Tensor(np.array(test_labels)))\n","testloader =  DataLoader(test_set, batch_size=64, train=False)"],"id":"0cdbc432","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"781b4da2"},"source":["### Word embeddings\n","\n","We will try different word embeddings and select the one which performs better. We create two functions: one to load the word embeddings and the other to create the embedding matrix."],"id":"781b4da2"},{"cell_type":"code","metadata":{"id":"31ea6341"},"source":["# Function to load the word embeddings\n","\n","def load_embedd(filename):\n","    words = []\n","    vectors = []\n","    file = open(filename,'r', encoding=\"utf8\")\n","    for line in file.readlines():\n","       row = line.split(' ')\n","       vocab = row[0]\n","       embd = row[1:len(row)]\n","       embd[-1] = embd[-1].rstrip()\n","       embd = list(map(float,embd)) # convert string to float\n","       words.append(vocab)\n","       vectors.append(embd)\n","    file.close()\n","    return words,vectors"],"id":"31ea6341","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bc4aef6f"},"source":["Function to create the embedding matrix."],"id":"bc4aef6f"},{"cell_type":"code","metadata":{"id":"aa5f5128"},"source":["# Function to create the embedding matrix\n","\n","def embed_matx(word_index, vocab, embeddings, length_vocab, length_embedding):\n","    embedding_matrix = np.zeros((length_vocab +1, length_embedding))\n","    for word, i in word_index.items():\n","        if word in vocab:\n","            idx = vocab.index(word)\n","            vector =  embeddings[idx]\n","            embedding_matrix[i] = vector\n","        if i == length_vocab:\n","            break\n","    return embedding_matrix"],"id":"aa5f5128","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"991cf6d2"},"source":["#### Glove (300 d)\n","\n","We use GloVe embeddings of dimension 300."],"id":"991cf6d2"},{"cell_type":"code","metadata":{"id":"dca6f8a7"},"source":["vocab_gv_300, vectors_gv_300 = load_embedd(filename = \"/content/drive/MyDrive/CS5344/Dataset/glove.6B.300d.txt\")"],"id":"dca6f8a7","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8b14586f"},"source":["Now we create the embbeding matrix."],"id":"8b14586f"},{"cell_type":"code","metadata":{"id":"3c454f83"},"source":["word_index = tokenizer.word_index\n","# Embedding matrix\n","embedding_matrix_gv_300 = embed_matx(word_index = word_index, \n","                                     vocab = vocab_gv_300, \n","                                     embeddings = vectors_gv_300, \n","                                     length_vocab = vocab_size, \n","                                     length_embedding = 300)"],"id":"3c454f83","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"82ceb5c6"},"source":["## Models\n","\n","First we define the CNN that we will use."],"id":"82ceb5c6"},{"cell_type":"code","metadata":{"id":"90be399d"},"source":["class CNN(nn.Module):\n","    def __init__(self, nlabels, train_parameters = True, random_embeddings = False): \n","        super().__init__()\n","        \n","        # Embedding layer\n","        self.embedding = nn.Embedding(num_embeddings =vocab_size+1, embedding_dim = 300)\n","        \n","        if random_embeddings == True:\n","            self.embedding.weight = nn.Parameter(torch.rand(vocab_size+1, 300), requires_grad = train_parameters)\n","        else:\n","            self.embedding.weight = nn.Parameter(torch.from_numpy(embedding_matrix_gv_300), requires_grad = train_parameters)\n","            \n","        # Filters for the CNN    \n","        self.filter_sizes = [2,3,4,5]\n","        self.num_filters = 50\n","        \n","        # Concolutional layers\n","        self.convs_concat = nn.ModuleList([nn.Conv2d(1, self.num_filters, (K, 300)) for K in self.filter_sizes])\n","        \n","        # Linear layers\n","        self.linear1 = nn.Linear(200,128)\n","  \n","        self.linear2 = nn.Linear(128,nlabels)\n","    \n","        self.relu = nn.ReLU()\n","        \n","        self.logsoftmax = nn.LogSoftmax(dim=1) \n","        \n","        \n","    def forward(self, x):\n","        # Embedding\n","        x = self.embedding(x)\n","        # Unsqueeze\n","        x = x.unsqueeze(1)\n","        # Convolution\n","        x = [F.relu(conv(x.float())).squeeze(3) for conv in self.convs_concat]\n","        # Max-pooling\n","        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x] \n","        x = torch.cat(x, 1)\n","        # Linear layers\n","        x = self.linear1(x)\n","        x = self.relu(x)\n","        x = self.linear2(x)\n","        x = self.logsoftmax(x) \n","        return x"],"id":"90be399d","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"86f2a4c8"},"source":["class CNN_extended(CNN):\n","    \n","    def __init__(self,nlabels, train_parameters, random_embeddings, epochs=100, lr=0.001):\n","        \n","        super().__init__(nlabels, train_parameters, random_embeddings)  \n","        self.lr = lr #Learning Rate\n","        self.optim = optim.Adam(self.parameters(), self.lr)\n","        self.epochs = epochs\n","        self.criterion = nn.NLLLoss()\n","        # A list to store the loss evolution along training\n","        self.loss_during_training = []\n","        self.valid_loss_during_training = []\n","        \n","    def trainloop(self,trainloader, validloader):\n","        # Optimization Loop\n","        for e in range(int(self.epochs)):\n","            start_time = time.time()\n","            # Random data permutation at each epoch\n","            running_loss = 0.\n","            i = 0\n","            length = 0\n","            accuracies = []\n","            \n","            for news, labels in trainloader:\n","                self.optim.zero_grad()  # Reset gradients\n","                out = self.forward(news.int())\n","                loss = self.criterion(out,labels.long())\n","                loss.backward()\n","                running_loss += loss.item()\n","                self.optim.step()\n","                top_p, top_class = out.topk(1, dim=1)\n","                equals = (top_class == labels.view(news.shape[0], 1))\n","                length += news.shape[0]\n","                accuracies.append(sum(equals))\n","                accuracy = sum(accuracies)/length\n","                i += 1\n","                if i%1000 == 0:\n","                    print(\" Train accuracy: \", accuracy)\n","                \n","            self.loss_during_training.append(running_loss/len(trainloader))\n","            \n","            # Validation Loss\n","            with torch.no_grad(): \n","               running_loss = 0.\n","               i = 0\n","               length = 0\n","               accuracies = []\n","               for news,labels in validloader:\n","                    out = self.forward(news.int())\n","                    loss = self.criterion(out,labels.long())\n","                    running_loss += loss.item()\n","                    top_p, top_class = out.topk(1, dim=1)\n","                    equals = (top_class == labels.view(news.shape[0], 1))\n","                    length += news.shape[0]\n","                    accuracies.append(sum(equals))\n","                    accuracy = sum(accuracies)/length\n","                print(\" Validation accuracy: \", accuracy)\n","                self.valid_loss_during_training.append(running_loss/len(validloader))\n","\n","            if(e % 1 == 0): # Every 10 epochs\n","              print(\"Training loss after %d epochs: %f\" \n","                      %(e,self.loss_during_training[-1]), \"Validation loss after %d epochs: %f\" %(e,self.valid_loss_during_training[-1]),\n","                      \"Time per epoch: %f seconds\"%(time.time() - start_time))"],"id":"86f2a4c8","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fa003f65"},"source":["We train the CNN in **4** different scenarios:\n","\n","  - **Random embeddings** + **Training embeddings**\n","  - **GloVe embeddings** + **Training embeddings**\n","  - **Random embeddings** + **Not training embeddings**\n","  - **GloVe embeddings** + **Not training embeddings**\n"," \n","We train the model for several epochs. This is done in order to select the optimal number of epochs, which occurs when the validation loss stops decreasing and starts increasing (Early Stopping). Sometimes the validation loss starts to increase after very few epochs. In those cases we stop the training prematurely since we already know the optimal number of epochs (this is what causes the \"KeyboardInterrupt\" message in some of the results which can be seen below)."],"id":"fa003f65"},{"cell_type":"markdown","metadata":{"id":"MWier48oxTd0"},"source":["### GloVe embeddings  + Not training embeddings"],"id":"MWier48oxTd0"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cf0c6983-f5bd-44ff-da99-245ea7bec223","executionInfo":{"status":"ok","timestamp":1665562912410,"user_tz":-480,"elapsed":7388970,"user":{"displayName":"Mansi Agarwal","userId":"01259360581954223859"}},"id":"aDjp8wu6xTd-"},"source":["# Initialize model\n","CNN_not_train_not_random = CNN_extended(nlabels = 6, \n","                                        epochs=9, \n","                                        lr=0.003, \n","                                        train_parameters = False, \n","                                        random_embeddings = False)\n","# Train model\n","CNN_not_train_not_random.trainloop(trainloader, validloader)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Train accuracy:  tensor([0.6604])\n"," Train accuracy:  tensor([0.6706])\n"," Train accuracy:  tensor([0.6778])\n"," Train accuracy:  tensor([0.6813])\n"," Train accuracy:  tensor([0.6840])\n"," Train accuracy:  tensor([0.6871])\n"," Train accuracy:  tensor([0.6894])\n"," Train accuracy:  tensor([0.6913])\n"," Train accuracy:  tensor([0.6926])\n"," Train accuracy:  tensor([0.6945])\n"," Train accuracy:  tensor([0.6959])\n"," Train accuracy:  tensor([0.6972])\n"," Train accuracy:  tensor([0.6983])\n"," Validation accuracy:  tensor([0.7089])\n","Training loss after 0 epochs: 0.855679 Validation loss after 0 epochs: 0.824699 Time per epoch: 828.016563 seconds\n"," Train accuracy:  tensor([0.7158])\n"," Train accuracy:  tensor([0.7158])\n"," Train accuracy:  tensor([0.7172])\n"," Train accuracy:  tensor([0.7171])\n"," Train accuracy:  tensor([0.7174])\n"," Train accuracy:  tensor([0.7185])\n"," Train accuracy:  tensor([0.7188])\n"," Train accuracy:  tensor([0.7195])\n"," Train accuracy:  tensor([0.7199])\n"," Train accuracy:  tensor([0.7206])\n"," Train accuracy:  tensor([0.7213])\n"," Train accuracy:  tensor([0.7219])\n"," Train accuracy:  tensor([0.7222])\n"," Validation accuracy:  tensor([0.7153])\n","Training loss after 1 epochs: 0.789085 Validation loss after 1 epochs: 0.816172 Time per epoch: 826.243865 seconds\n"," Train accuracy:  tensor([0.7319])\n"," Train accuracy:  tensor([0.7312])\n"," Train accuracy:  tensor([0.7320])\n"," Train accuracy:  tensor([0.7315])\n"," Train accuracy:  tensor([0.7314])\n"," Train accuracy:  tensor([0.7320])\n"," Train accuracy:  tensor([0.7325])\n"," Train accuracy:  tensor([0.7329])\n"," Train accuracy:  tensor([0.7332])\n"," Train accuracy:  tensor([0.7336])\n"," Train accuracy:  tensor([0.7340])\n"," Train accuracy:  tensor([0.7343])\n"," Train accuracy:  tensor([0.7344])\n"," Validation accuracy:  tensor([0.7163])\n","Training loss after 2 epochs: 0.755728 Validation loss after 2 epochs: 0.834010 Time per epoch: 822.528229 seconds\n"," Train accuracy:  tensor([0.7390])\n"," Train accuracy:  tensor([0.7386])\n"," Train accuracy:  tensor([0.7399])\n"," Train accuracy:  tensor([0.7395])\n"," Train accuracy:  tensor([0.7391])\n"," Train accuracy:  tensor([0.7400])\n"," Train accuracy:  tensor([0.7402])\n"," Train accuracy:  tensor([0.7407])\n"," Train accuracy:  tensor([0.7410])\n"," Train accuracy:  tensor([0.7414])\n"," Train accuracy:  tensor([0.7418])\n"," Train accuracy:  tensor([0.7422])\n"," Train accuracy:  tensor([0.7423])\n"," Validation accuracy:  tensor([0.7127])\n","Training loss after 3 epochs: 0.733725 Validation loss after 3 epochs: 0.841199 Time per epoch: 817.959787 seconds\n"," Train accuracy:  tensor([0.7468])\n"," Train accuracy:  tensor([0.7455])\n"," Train accuracy:  tensor([0.7468])\n"," Train accuracy:  tensor([0.7463])\n"," Train accuracy:  tensor([0.7460])\n"," Train accuracy:  tensor([0.7470])\n"," Train accuracy:  tensor([0.7473])\n"," Train accuracy:  tensor([0.7475])\n"," Train accuracy:  tensor([0.7478])\n"," Train accuracy:  tensor([0.7481])\n"," Train accuracy:  tensor([0.7485])\n"," Train accuracy:  tensor([0.7487])\n"," Train accuracy:  tensor([0.7486])\n"," Validation accuracy:  tensor([0.7145])\n","Training loss after 4 epochs: 0.716463 Validation loss after 4 epochs: 0.855254 Time per epoch: 818.271845 seconds\n"," Train accuracy:  tensor([0.7514])\n"," Train accuracy:  tensor([0.7503])\n"," Train accuracy:  tensor([0.7511])\n"," Train accuracy:  tensor([0.7505])\n"," Train accuracy:  tensor([0.7504])\n"," Train accuracy:  tensor([0.7511])\n"," Train accuracy:  tensor([0.7514])\n"," Train accuracy:  tensor([0.7518])\n"," Train accuracy:  tensor([0.7521])\n"," Train accuracy:  tensor([0.7525])\n"," Train accuracy:  tensor([0.7529])\n"," Train accuracy:  tensor([0.7530])\n"," Train accuracy:  tensor([0.7530])\n"," Validation accuracy:  tensor([0.7129])\n","Training loss after 5 epochs: 0.703485 Validation loss after 5 epochs: 0.861882 Time per epoch: 821.168440 seconds\n"," Train accuracy:  tensor([0.7578])\n"," Train accuracy:  tensor([0.7555])\n"," Train accuracy:  tensor([0.7560])\n"," Train accuracy:  tensor([0.7553])\n"," Train accuracy:  tensor([0.7551])\n"," Train accuracy:  tensor([0.7559])\n"," Train accuracy:  tensor([0.7560])\n"," Train accuracy:  tensor([0.7561])\n"," Train accuracy:  tensor([0.7563])\n"," Train accuracy:  tensor([0.7566])\n"," Train accuracy:  tensor([0.7570])\n"," Train accuracy:  tensor([0.7571])\n"," Train accuracy:  tensor([0.7571])\n"," Validation accuracy:  tensor([0.7121])\n","Training loss after 6 epochs: 0.692515 Validation loss after 6 epochs: 0.867005 Time per epoch: 821.366730 seconds\n"," Train accuracy:  tensor([0.7600])\n"," Train accuracy:  tensor([0.7584])\n"," Train accuracy:  tensor([0.7589])\n"," Train accuracy:  tensor([0.7582])\n"," Train accuracy:  tensor([0.7580])\n"," Train accuracy:  tensor([0.7589])\n"," Train accuracy:  tensor([0.7594])\n"," Train accuracy:  tensor([0.7595])\n"," Train accuracy:  tensor([0.7595])\n"," Train accuracy:  tensor([0.7596])\n"," Train accuracy:  tensor([0.7601])\n"," Train accuracy:  tensor([0.7602])\n"," Train accuracy:  tensor([0.7602])\n"," Validation accuracy:  tensor([0.7113])\n","Training loss after 7 epochs: 0.682890 Validation loss after 7 epochs: 0.879561 Time per epoch: 810.681794 seconds\n"," Train accuracy:  tensor([0.7633])\n"," Train accuracy:  tensor([0.7615])\n"," Train accuracy:  tensor([0.7623])\n"," Train accuracy:  tensor([0.7612])\n"," Train accuracy:  tensor([0.7611])\n"," Train accuracy:  tensor([0.7619])\n"," Train accuracy:  tensor([0.7623])\n"," Train accuracy:  tensor([0.7625])\n"," Train accuracy:  tensor([0.7624])\n"," Train accuracy:  tensor([0.7624])\n"," Train accuracy:  tensor([0.7628])\n"," Train accuracy:  tensor([0.7629])\n"," Train accuracy:  tensor([0.7628])\n"," Validation accuracy:  tensor([0.7109])\n","Training loss after 8 epochs: 0.675071 Validation loss after 8 epochs: 0.886414 Time per epoch: 821.613119 seconds\n"]}],"id":"aDjp8wu6xTd-"},{"cell_type":"markdown","metadata":{"id":"358c8b67"},"source":["### Random embeddings  + Training embeddings"],"id":"358c8b67"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"87b6b117","outputId":"14176d42-42b8-40f0-966f-8df3f9b00be4"},"source":["# Initialize model\n","CNN_train_random = CNN_extended(nlabels = 6, epochs=5, lr=0.003, train_parameters = True, random_embeddings = True)\n","# Train model\n","CNN_train_random.trainloop(trainloader, validloader)"],"id":"87b6b117","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":[" Train accuracy:  tensor([0.5957])\n"," Train accuracy:  tensor([0.6299])\n"," Train accuracy:  tensor([0.6476])\n"," Train accuracy:  tensor([0.6581])\n"," Train accuracy:  tensor([0.6661])\n"," Train accuracy:  tensor([0.6726])\n"," Train accuracy:  tensor([0.6772])\n"," Train accuracy:  tensor([0.6813])\n"," Train accuracy:  tensor([0.6849])\n"," Validation accuracy:  tensor([0.7139])\n","Training loss after 0 epochs: 0.881487 Validation loss after 0 epochs: 0.812628 Time per epoch: 6060.227753 seconds\n"," Train accuracy:  tensor([0.7296])\n"," Train accuracy:  tensor([0.7350])\n"," Train accuracy:  tensor([0.7385])\n"," Train accuracy:  tensor([0.7408])\n"," Train accuracy:  tensor([0.7430])\n"," Train accuracy:  tensor([0.7449])\n"," Train accuracy:  tensor([0.7463])\n"," Train accuracy:  tensor([0.7477])\n"," Train accuracy:  tensor([0.7493])\n"," Validation accuracy:  tensor([0.7138])\n","Training loss after 1 epochs: 0.711673 Validation loss after 1 epochs: 0.837501 Time per epoch: 7207.740807 seconds\n"," Train accuracy:  tensor([0.7730])\n"," Train accuracy:  tensor([0.7778])\n"," Train accuracy:  tensor([0.7797])\n"," Train accuracy:  tensor([0.7817])\n"," Train accuracy:  tensor([0.7836])\n"," Train accuracy:  tensor([0.7848])\n"," Train accuracy:  tensor([0.7857])\n"," Train accuracy:  tensor([0.7864])\n"," Train accuracy:  tensor([0.7874])\n"," Validation accuracy:  tensor([0.7122])\n","Training loss after 2 epochs: 0.612557 Validation loss after 2 epochs: 0.873512 Time per epoch: 7261.114381 seconds\n"," Train accuracy:  tensor([0.8048])\n"," Train accuracy:  tensor([0.8084])\n"," Train accuracy:  tensor([0.8091])\n"," Train accuracy:  tensor([0.8099])\n"," Train accuracy:  tensor([0.8111])\n"," Train accuracy:  tensor([0.8118])\n"," Train accuracy:  tensor([0.8123])\n"," Train accuracy:  tensor([0.8127])\n"," Train accuracy:  tensor([0.8133])\n"," Validation accuracy:  tensor([0.7077])\n","Training loss after 3 epochs: 0.542114 Validation loss after 3 epochs: 0.921283 Time per epoch: 7266.223625 seconds\n"," Train accuracy:  tensor([0.8261])\n"," Train accuracy:  tensor([0.8286])\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-5a972d7112d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mCNN_train_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mCNN_train_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-32-126a2a95584d>\u001b[0m in \u001b[0;36mtrainloop\u001b[0;34m(self, trainloader, validloader)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mtop_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    116\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"525d5d4a"},"source":["### GloVe embeddings  + Training embeddings"],"id":"525d5d4a"},{"cell_type":"code","metadata":{"id":"e0ab5a99"},"source":["# Initialize model\n","CNN_train_not_random = CNN_extended(nlabels = 6, epochs=4, lr=0.003, train_parameters = True, random_embeddings = False)\n","# Train model\n","CNN_train_not_random.trainloop(trainloader, validloader)"],"id":"e0ab5a99","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f37d85d1"},"source":["### Random embeddings  + Not training embeddings"],"id":"f37d85d1"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"74c7d4f8","outputId":"f60aa807-e4cd-47a0-bc14-d6ad6b385c42"},"source":["# Initialize model\n","CNN_not_train_random = CNN_extended(nlabels = 6, epochs=9, lr=0.003, train_parameters = False, random_embeddings = True)\n","# Train model\n","CNN_not_train_random.trainloop(trainloader, validloader)"],"id":"74c7d4f8","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":[" Train accuracy:  tensor([0.5501])\n"," Train accuracy:  tensor([0.5608])\n"," Train accuracy:  tensor([0.5671])\n"," Train accuracy:  tensor([0.5729])\n"," Train accuracy:  tensor([0.5778])\n"," Train accuracy:  tensor([0.5820])\n"," Train accuracy:  tensor([0.5851])\n"," Train accuracy:  tensor([0.5879])\n"," Train accuracy:  tensor([0.5903])\n"," Validation accuracy:  tensor([0.6015])\n","Training loss after 0 epochs: 1.121780 Validation loss after 0 epochs: 1.108112 Time per epoch: 635.669165 seconds\n"," Train accuracy:  tensor([0.6119])\n"," Train accuracy:  tensor([0.6135])\n"," Train accuracy:  tensor([0.6132])\n"," Train accuracy:  tensor([0.6132])\n"," Train accuracy:  tensor([0.6138])\n"," Train accuracy:  tensor([0.6145])\n"," Train accuracy:  tensor([0.6152])\n"," Train accuracy:  tensor([0.6157])\n"," Train accuracy:  tensor([0.6164])\n"," Validation accuracy:  tensor([0.6112])\n","Training loss after 1 epochs: 1.062122 Validation loss after 1 epochs: 1.081675 Time per epoch: 637.249443 seconds\n"," Train accuracy:  tensor([0.6229])\n"," Train accuracy:  tensor([0.6240])\n"," Train accuracy:  tensor([0.6228])\n"," Train accuracy:  tensor([0.6233])\n"," Train accuracy:  tensor([0.6236])\n"," Train accuracy:  tensor([0.6239])\n"," Train accuracy:  tensor([0.6244])\n"," Train accuracy:  tensor([0.6247])\n"," Train accuracy:  tensor([0.6253])\n"," Validation accuracy:  tensor([0.6222])\n","Training loss after 2 epochs: 1.042205 Validation loss after 2 epochs: 1.062248 Time per epoch: 634.489743 seconds\n"," Train accuracy:  tensor([0.6297])\n"," Train accuracy:  tensor([0.6298])\n"," Train accuracy:  tensor([0.6285])\n"," Train accuracy:  tensor([0.6284])\n"," Train accuracy:  tensor([0.6288])\n"," Train accuracy:  tensor([0.6292])\n"," Train accuracy:  tensor([0.6296])\n"," Train accuracy:  tensor([0.6299])\n"," Train accuracy:  tensor([0.6303])\n"," Validation accuracy:  tensor([0.6246])\n","Training loss after 3 epochs: 1.030901 Validation loss after 3 epochs: 1.055378 Time per epoch: 628.260647 seconds\n"," Train accuracy:  tensor([0.6310])\n"," Train accuracy:  tensor([0.6324])\n"," Train accuracy:  tensor([0.6314])\n"," Train accuracy:  tensor([0.6315])\n"," Train accuracy:  tensor([0.6318])\n"," Train accuracy:  tensor([0.6322])\n"," Train accuracy:  tensor([0.6325])\n"," Train accuracy:  tensor([0.6327])\n"," Train accuracy:  tensor([0.6332])\n"," Validation accuracy:  tensor([0.6273])\n","Training loss after 4 epochs: 1.024776 Validation loss after 4 epochs: 1.046851 Time per epoch: 651.401029 seconds\n"," Train accuracy:  tensor([0.6340])\n"," Train accuracy:  tensor([0.6344])\n"," Train accuracy:  tensor([0.6337])\n"," Train accuracy:  tensor([0.6336])\n"," Train accuracy:  tensor([0.6340])\n"," Train accuracy:  tensor([0.6342])\n"," Train accuracy:  tensor([0.6344])\n"," Train accuracy:  tensor([0.6345])\n"," Train accuracy:  tensor([0.6350])\n"," Validation accuracy:  tensor([0.6323])\n","Training loss after 5 epochs: 1.019743 Validation loss after 5 epochs: 1.033113 Time per epoch: 677.647488 seconds\n"," Train accuracy:  tensor([0.6350])\n"," Train accuracy:  tensor([0.6362])\n"," Train accuracy:  tensor([0.6354])\n"," Train accuracy:  tensor([0.6353])\n"," Train accuracy:  tensor([0.6357])\n"," Train accuracy:  tensor([0.6358])\n"," Train accuracy:  tensor([0.6362])\n"," Train accuracy:  tensor([0.6364])\n"," Train accuracy:  tensor([0.6368])\n"," Validation accuracy:  tensor([0.6341])\n","Training loss after 6 epochs: 1.015542 Validation loss after 6 epochs: 1.027596 Time per epoch: 692.991172 seconds\n"," Train accuracy:  tensor([0.6381])\n"," Train accuracy:  tensor([0.6381])\n"," Train accuracy:  tensor([0.6371])\n"," Train accuracy:  tensor([0.6371])\n"," Train accuracy:  tensor([0.6376])\n"," Train accuracy:  tensor([0.6378])\n"," Train accuracy:  tensor([0.6381])\n"," Train accuracy:  tensor([0.6383])\n"," Train accuracy:  tensor([0.6387])\n"," Validation accuracy:  tensor([0.6345])\n","Training loss after 7 epochs: 1.011294 Validation loss after 7 epochs: 1.024060 Time per epoch: 833.903002 seconds\n"," Train accuracy:  tensor([0.6385])\n"," Train accuracy:  tensor([0.6386])\n"," Train accuracy:  tensor([0.6384])\n"," Train accuracy:  tensor([0.6383])\n"," Train accuracy:  tensor([0.6387])\n"," Train accuracy:  tensor([0.6390])\n"," Train accuracy:  tensor([0.6393])\n"," Train accuracy:  tensor([0.6396])\n"," Train accuracy:  tensor([0.6399])\n"," Validation accuracy:  tensor([0.6362])\n","Training loss after 8 epochs: 1.007963 Validation loss after 8 epochs: 1.019992 Time per epoch: 895.114388 seconds\n"]}]},{"cell_type":"markdown","metadata":{"id":"2aadf419"},"source":["## Testing performance\n","\n","We join the **train** and **validation** datasets and we train the model with this dataset using the optimal number of epochs. Then we evaluate the model with the **test** set. First we need to modify a bit the class used previously."],"id":"2aadf419"},{"cell_type":"code","metadata":{"id":"c1bdb6d1"},"source":["class CNN_extended(CNN):\n","    \n","    def __init__(self,nlabels, train_parameters, random_embeddings, epochs=100,lr=0.001):\n","        \n","        super().__init__(nlabels, train_parameters, random_embeddings)  \n","        \n","        self.lr = lr #Learning Rate\n","        \n","        self.optim = optim.Adam(self.parameters(), self.lr)\n","        \n","        self.epochs = epochs\n","        \n","        self.criterion = nn.NLLLoss()               \n","        \n","        # A list to store the loss evolution along training\n","        \n","        self.loss_during_training = [] \n","\n","        self.valid_loss_during_training = []\n","        \n","    def trainloop(self,trainloader):\n","        \n","        \n","        # Optimization Loop\n","        \n","        for e in range(int(self.epochs)):\n","\n","            start_time = time.time()\n","            \n","            # Random data permutation at each epoch\n","            \n","            running_loss = 0.\n","            \n","            i = 0\n","            \n","            length = 0\n","            \n","            accuracies = []\n","            \n","            for news, labels in trainloader:             \n","        \n","                self.optim.zero_grad()  # Reset gradients\n","            \n","                out = self.forward(news.int())\n","\n","                loss = self.criterion(out,labels.long())\n","                \n","                loss.backward()\n","\n","                running_loss += loss.item()\n","\n","                self.optim.step()\n","                \n","                top_p, top_class = out.topk(1, dim=1)\n","                \n","                equals = (top_class == labels.view(news.shape[0], 1))\n","                \n","                length += news.shape[0]\n","                \n","                accuracies.append(sum(equals)) \n","                \n","                accuracy = sum(accuracies)/length\n","                \n","                i += 1\n","                \n","                if i%1000 == 0:\n","                    print(\" Train accuracy: \", accuracy)\n","                \n","            self.loss_during_training.append(running_loss/len(trainloader))\n","            end_time = time.time()\n","            print(\"Elapsed time: \", end_time-start_time)\n","\n","                \n","    def eval_performance(self,dataloader):\n","        predictions = np.empty((1,1))\n","\n","        with torch.no_grad():\n","\n","            for news,labels in dataloader:\n","                \n","                logprobs = self.forward(news)  \n","                top_p, top_class = logprobs.topk(1, dim=1)\n","                \n","                top_class_array = np.array(top_class)\n","                predictions = np.concatenate((predictions, top_class_array), axis = 0)\n","                \n","        return predictions[1:]"],"id":"c1bdb6d1","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"045b5f20"},"source":["Now we join the train and validation sets."],"id":"045b5f20"},{"cell_type":"code","metadata":{"id":"7d243cda"},"source":["# Join train and validation sequences\n","train_valid_tokenized_pad = np.concatenate((train_tokenized_pad, valid_tokenized_pad), axis = 0)\n","# Join train and validation labels\n","train_valid_labels = np.concatenate((np.array(train_labels), np.array(valid_labels)), axis = 0)\n","\n","# Create tensor objects\n","\n","# Train + validation\n","train_valid_tensor = torch.Tensor(train_valid_tokenized_pad).int()\n","# Test\n","test_tensor =  torch.Tensor(test_tokenized_pad).int()\n","\n","# Tranform tensors into data loader objects\n","\n","# Train + validation\n","train_valid_set = TensorDataset(train_valid_tensor, torch.Tensor(np.array(train_valid_labels)))\n","train_valid_loader = DataLoader(train_valid_set, batch_size=60)\n","# Test\n","test_set = TensorDataset(test_tensor, torch.Tensor(np.array(test_labels)))\n","testloader =  DataLoader(test_set, batch_size=60)"],"id":"7d243cda","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4cb3c5d4"},"source":["### Random embeddings  + Training embeddings"],"id":"4cb3c5d4"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f0e7b4f4","outputId":"f4a2952f-d3da-4e7d-d4ae-fc7ccbd15f76"},"source":["# Initialize model\n","CNN_test_train_random = CNN_extended(nlabels = 6, epochs=1, lr=0.003, train_parameters = True, random_embeddings = True)\n","# Train model\n","CNN_test_train_random.trainloop(train_valid_loader)\n","# Get predictions\n","predictions1 = CNN_test_train_random.eval_performance(testloader)"],"id":"f0e7b4f4","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":[" Train accuracy:  tensor([0.5919])\n"," Train accuracy:  tensor([0.6198])\n"," Train accuracy:  tensor([0.6408])\n"," Train accuracy:  tensor([0.6534])\n"," Train accuracy:  tensor([0.6628])\n"," Train accuracy:  tensor([0.6697])\n"," Train accuracy:  tensor([0.6752])\n"," Train accuracy:  tensor([0.6800])\n"," Train accuracy:  tensor([0.6841])\n"," Train accuracy:  tensor([0.6874])\n","Elapsed time:  7168.229678869247\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f64b0527","outputId":"3a5199fc-6a2d-4581-fd01-21a776e84aa1"},"source":["print(classification_report(np.array(test_labels).reshape(len(test_labels),1), predictions1))"],"id":"f64b0527","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.71      0.87      0.79     23507\n","           1       0.63      0.26      0.37      3514\n","           2       0.70      0.48      0.57     11297\n","           3       0.72      0.07      0.13      1224\n","           4       0.75      0.84      0.79     17472\n","           5       0.71      0.54      0.61      2305\n","\n","    accuracy                           0.72     59319\n","   macro avg       0.70      0.51      0.54     59319\n","weighted avg       0.72      0.72      0.70     59319\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UZGve0Wp5XMu","outputId":"25926e5f-2712-4589-ae1e-69d5abc01400"},"source":["# Classification report without 'true' label\n","print(classification_report(np.array(test_labels).reshape(len(test_labels),1), predictions1, labels = [1,2,3,4,5]))"],"id":"UZGve0Wp5XMu","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           1       0.63      0.26      0.37      3514\n","           2       0.70      0.48      0.57     11297\n","           3       0.72      0.07      0.13      1224\n","           4       0.75      0.84      0.79     17472\n","           5       0.71      0.54      0.61      2305\n","\n","   micro avg       0.73      0.62      0.67     35812\n","   macro avg       0.70      0.44      0.49     35812\n","weighted avg       0.72      0.62      0.65     35812\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g8c8aXFn5Wl1","outputId":"bffd1e1f-6e75-4a7b-e7b6-1b41d909c33c"},"source":["# Confusion matrix\n","print(confusion_matrix(np.array(test_labels).reshape(len(test_labels),1), predictions1))"],"id":"g8c8aXFn5Wl1","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[[20543   198  1057    12  1512   185]\n"," [ 1439   923   206     5   885    56]\n"," [ 3499   109  5391     7  2113   178]\n"," [  796    55    87    85   170    31]\n"," [ 1803   139   791     5 14672    62]\n"," [  706    51   131     4   172  1241]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"fe5ad30b"},"source":["### GloVe embeddings  + Training embeddings"],"id":"fe5ad30b"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8797421","outputId":"55f6012f-40fb-4ec6-c58f-ba47f1afa587"},"source":["# Initialize model\n","CNN_test_train_not_random = CNN_extended(nlabels = 6, epochs=1, lr=0.003, train_parameters = True, random_embeddings = False)\n","# Train model\n","CNN_test_train_not_random.trainloop(train_valid_loader)\n","# Get predictions\n","predictions_2 = CNN_test_train_not_random.eval_performance(testloader)"],"id":"c8797421","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":[" Train accuracy:  tensor([0.6673])\n"," Train accuracy:  tensor([0.6831])\n"," Train accuracy:  tensor([0.6921])\n"," Train accuracy:  tensor([0.6976])\n"," Train accuracy:  tensor([0.7028])\n"," Train accuracy:  tensor([0.7066])\n"," Train accuracy:  tensor([0.7096])\n"," Train accuracy:  tensor([0.7120])\n"," Train accuracy:  tensor([0.7144])\n"," Train accuracy:  tensor([0.7164])\n","Elapsed time:  9102.66008424759\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"77e3853a","outputId":"0df46398-5599-4153-f3fe-21866161a6bf"},"source":["print(classification_report(np.array(test_labels).reshape(len(test_labels),1), predictions_2))"],"id":"77e3853a","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.74      0.87      0.80     23507\n","           1       0.67      0.35      0.46      3514\n","           2       0.71      0.54      0.61     11297\n","           3       0.70      0.11      0.19      1224\n","           4       0.76      0.83      0.80     17472\n","           5       0.74      0.58      0.65      2305\n","\n","    accuracy                           0.74     59319\n","   macro avg       0.72      0.55      0.58     59319\n","weighted avg       0.73      0.74      0.72     59319\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x6xDZyYx5xEz","outputId":"ba99f564-66b8-42cc-8c01-ffcbeffaf89a"},"source":["# Classification report without 'true' label\n","print(classification_report(np.array(test_labels).reshape(len(test_labels),1), predictions_2, labels = [1,2,3,4,5]))"],"id":"x6xDZyYx5xEz","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           1       0.67      0.35      0.46      3514\n","           2       0.71      0.54      0.61     11297\n","           3       0.70      0.11      0.19      1224\n","           4       0.76      0.83      0.80     17472\n","           5       0.74      0.58      0.65      2305\n","\n","   micro avg       0.74      0.65      0.69     35812\n","   macro avg       0.71      0.48      0.54     35812\n","weighted avg       0.73      0.65      0.67     35812\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"umI_sor55xkl","outputId":"c247199a-0237-4ff7-8dc9-a07f1bdd3f03"},"source":["# Confusion matrix\n","print(confusion_matrix(np.array(test_labels).reshape(len(test_labels),1), predictions_2))"],"id":"umI_sor55xkl","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[[20466   212  1159    33  1474   163]\n"," [ 1278  1223   147     6   806    54]\n"," [ 3044   131  6078    13  1862   169]\n"," [  738    44    94   131   188    29]\n"," [ 1679   181  1010     4 14541    57]\n"," [  633    45    93     1   192  1341]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"6ae61424"},"source":["### Random embeddings  +  Not training embeddings"],"id":"6ae61424"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e25f549b","outputId":"7fa6bb9d-5b84-41a8-9f48-5806a7981cd1"},"source":["# Initialize model\n","CNN_test_not_train_random = CNN_extended(nlabels = 6, epochs=9, lr=0.003, train_parameters = False, random_embeddings = True)\n","# Train model\n","CNN_test_not_train_random.trainloop(train_valid_loader)\n","# Get predictions\n","predictions_3 = CNN_test_not_train_random.eval_performance(testloader)"],"id":"e25f549b","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":[" Train accuracy:  tensor([0.5530])\n"," Train accuracy:  tensor([0.5597])\n"," Train accuracy:  tensor([0.5638])\n"," Train accuracy:  tensor([0.5688])\n"," Train accuracy:  tensor([0.5730])\n"," Train accuracy:  tensor([0.5763])\n"," Train accuracy:  tensor([0.5796])\n"," Train accuracy:  tensor([0.5827])\n"," Train accuracy:  tensor([0.5856])\n"," Train accuracy:  tensor([0.5880])\n","Elapsed time:  743.8465197086334\n"," Train accuracy:  tensor([0.6123])\n"," Train accuracy:  tensor([0.6118])\n"," Train accuracy:  tensor([0.6123])\n"," Train accuracy:  tensor([0.6127])\n"," Train accuracy:  tensor([0.6134])\n"," Train accuracy:  tensor([0.6141])\n"," Train accuracy:  tensor([0.6147])\n"," Train accuracy:  tensor([0.6150])\n"," Train accuracy:  tensor([0.6156])\n"," Train accuracy:  tensor([0.6159])\n","Elapsed time:  741.4050281047821\n"," Train accuracy:  tensor([0.6202])\n"," Train accuracy:  tensor([0.6200])\n"," Train accuracy:  tensor([0.6203])\n"," Train accuracy:  tensor([0.6208])\n"," Train accuracy:  tensor([0.6211])\n"," Train accuracy:  tensor([0.6217])\n"," Train accuracy:  tensor([0.6220])\n"," Train accuracy:  tensor([0.6223])\n"," Train accuracy:  tensor([0.6228])\n"," Train accuracy:  tensor([0.6231])\n","Elapsed time:  735.0587935447693\n"," Train accuracy:  tensor([0.6248])\n"," Train accuracy:  tensor([0.6242])\n"," Train accuracy:  tensor([0.6247])\n"," Train accuracy:  tensor([0.6246])\n"," Train accuracy:  tensor([0.6249])\n"," Train accuracy:  tensor([0.6252])\n"," Train accuracy:  tensor([0.6253])\n"," Train accuracy:  tensor([0.6254])\n"," Train accuracy:  tensor([0.6259])\n"," Train accuracy:  tensor([0.6261])\n","Elapsed time:  742.421392917633\n"," Train accuracy:  tensor([0.6267])\n"," Train accuracy:  tensor([0.6266])\n"," Train accuracy:  tensor([0.6264])\n"," Train accuracy:  tensor([0.6265])\n"," Train accuracy:  tensor([0.6271])\n"," Train accuracy:  tensor([0.6275])\n"," Train accuracy:  tensor([0.6277])\n"," Train accuracy:  tensor([0.6279])\n"," Train accuracy:  tensor([0.6283])\n"," Train accuracy:  tensor([0.6284])\n","Elapsed time:  757.4541792869568\n"," Train accuracy:  tensor([0.6299])\n"," Train accuracy:  tensor([0.6288])\n"," Train accuracy:  tensor([0.6288])\n"," Train accuracy:  tensor([0.6286])\n"," Train accuracy:  tensor([0.6289])\n"," Train accuracy:  tensor([0.6291])\n"," Train accuracy:  tensor([0.6292])\n"," Train accuracy:  tensor([0.6292])\n"," Train accuracy:  tensor([0.6295])\n"," Train accuracy:  tensor([0.6296])\n","Elapsed time:  782.0601441860199\n"," Train accuracy:  tensor([0.6310])\n"," Train accuracy:  tensor([0.6302])\n"," Train accuracy:  tensor([0.6298])\n"," Train accuracy:  tensor([0.6298])\n"," Train accuracy:  tensor([0.6299])\n"," Train accuracy:  tensor([0.6303])\n"," Train accuracy:  tensor([0.6303])\n"," Train accuracy:  tensor([0.6302])\n"," Train accuracy:  tensor([0.6306])\n"," Train accuracy:  tensor([0.6306])\n","Elapsed time:  836.1870765686035\n"," Train accuracy:  tensor([0.6324])\n"," Train accuracy:  tensor([0.6313])\n"," Train accuracy:  tensor([0.6309])\n"," Train accuracy:  tensor([0.6307])\n"," Train accuracy:  tensor([0.6308])\n"," Train accuracy:  tensor([0.6311])\n"," Train accuracy:  tensor([0.6311])\n"," Train accuracy:  tensor([0.6309])\n"," Train accuracy:  tensor([0.6312])\n"," Train accuracy:  tensor([0.6311])\n","Elapsed time:  902.3521666526794\n"," Train accuracy:  tensor([0.6333])\n"," Train accuracy:  tensor([0.6323])\n"," Train accuracy:  tensor([0.6316])\n"," Train accuracy:  tensor([0.6315])\n"," Train accuracy:  tensor([0.6314])\n"," Train accuracy:  tensor([0.6317])\n"," Train accuracy:  tensor([0.6316])\n"," Train accuracy:  tensor([0.6315])\n"," Train accuracy:  tensor([0.6318])\n"," Train accuracy:  tensor([0.6318])\n","Elapsed time:  902.0216271877289\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8f068b98","outputId":"cbeb5654-2284-4081-ee94-eb126935d175"},"source":["print(classification_report(np.array(test_labels).reshape(len(test_labels),1), predictions_3))"],"id":"8f068b98","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.63      0.81      0.71     23507\n","           1       0.81      0.03      0.06      3514\n","           2       0.52      0.34      0.41     11297\n","           3       0.30      0.02      0.04      1224\n","           4       0.67      0.78      0.72     17472\n","           5       0.69      0.29      0.41      2305\n","\n","    accuracy                           0.63     59319\n","   macro avg       0.60      0.38      0.39     59319\n","weighted avg       0.63      0.63      0.59     59319\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H34ptx3whpOS","outputId":"4b0541c3-4649-4036-9da9-8038119847cc"},"source":["# Classification report without 'true' label\n","print(classification_report(np.array(test_labels).reshape(len(test_labels),1), predictions_3, labels = [1,2,3,4,5]))"],"id":"H34ptx3whpOS","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           1       0.81      0.03      0.06      3514\n","           2       0.52      0.34      0.41     11297\n","           3       0.30      0.02      0.04      1224\n","           4       0.67      0.78      0.72     17472\n","           5       0.69      0.29      0.41      2305\n","\n","   micro avg       0.63      0.51      0.56     35812\n","   macro avg       0.60      0.29      0.33     35812\n","weighted avg       0.62      0.51      0.51     35812\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1koxLr3NhpDw","outputId":"baa0ed16-8c0c-42d3-fdec-787cf74cc78e"},"source":["# Confusion matrix\n","print(confusion_matrix(np.array(test_labels).reshape(len(test_labels),1), predictions_3))"],"id":"1koxLr3NhpDw","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[[19038    13  1838    22  2467   129]\n"," [ 2119   112   288     8   953    34]\n"," [ 4362     5  3845     3  2992    90]\n"," [  904     0   123    29   150    18]\n"," [ 2792     7   974    24 13640    35]\n"," [ 1093     2   307    11   221   671]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"e43a272b"},"source":["### GloVe embeddings  +  Not training embeddings"],"id":"e43a272b"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"430ceef0","outputId":"3e8e65d7-c76e-41ae-f4a3-7f06aa08e7cd"},"source":["# Initialize model\n","CNN_test_not_train_not_random = CNN_extended(nlabels = 6, epochs=10, lr=0.01, train_parameters = False, random_embeddings = False)\n","# Train model\n","CNN_test_not_train_not_random.trainloop(train_valid_loader)\n","# Get predictions\n","predictions_4 = CNN_test_not_train_not_random.eval_performance(testloader)"],"id":"430ceef0","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Train accuracy:  tensor([0.6508])\n"," Train accuracy:  tensor([0.6585])\n"," Train accuracy:  tensor([0.6636])\n"," Train accuracy:  tensor([0.6656])\n"," Train accuracy:  tensor([0.6670])\n"," Train accuracy:  tensor([0.6699])\n"," Train accuracy:  tensor([0.6718])\n"," Train accuracy:  tensor([0.6730])\n"," Train accuracy:  tensor([0.6737])\n"," Train accuracy:  tensor([0.6749])\n"," Train accuracy:  tensor([0.6757])\n"," Train accuracy:  tensor([0.6765])\n"," Train accuracy:  tensor([0.6771])\n"," Train accuracy:  tensor([0.6776])\n","Elapsed time:  894.5855877399445\n"," Train accuracy:  tensor([0.6887])\n"," Train accuracy:  tensor([0.6872])\n"," Train accuracy:  tensor([0.6876])\n"," Train accuracy:  tensor([0.6877])\n"," Train accuracy:  tensor([0.6874])\n"," Train accuracy:  tensor([0.6884])\n"," Train accuracy:  tensor([0.6893])\n"," Train accuracy:  tensor([0.6893])\n"," Train accuracy:  tensor([0.6892])\n"," Train accuracy:  tensor([0.6898])\n"," Train accuracy:  tensor([0.6901])\n"," Train accuracy:  tensor([0.6907])\n"," Train accuracy:  tensor([0.6908])\n"," Train accuracy:  tensor([0.6910])\n","Elapsed time:  898.1726748943329\n"," Train accuracy:  tensor([0.6945])\n"," Train accuracy:  tensor([0.6942])\n"," Train accuracy:  tensor([0.6949])\n"," Train accuracy:  tensor([0.6949])\n"," Train accuracy:  tensor([0.6945])\n"," Train accuracy:  tensor([0.6952])\n"," Train accuracy:  tensor([0.6959])\n"," Train accuracy:  tensor([0.6960])\n"," Train accuracy:  tensor([0.6958])\n"," Train accuracy:  tensor([0.6964])\n"," Train accuracy:  tensor([0.6964])\n"," Train accuracy:  tensor([0.6967])\n"," Train accuracy:  tensor([0.6969])\n"," Train accuracy:  tensor([0.6970])\n","Elapsed time:  893.8608975410461\n"," Train accuracy:  tensor([0.6992])\n"," Train accuracy:  tensor([0.6993])\n"," Train accuracy:  tensor([0.6994])\n"," Train accuracy:  tensor([0.6990])\n"," Train accuracy:  tensor([0.6987])\n"," Train accuracy:  tensor([0.6996])\n"," Train accuracy:  tensor([0.7000])\n"," Train accuracy:  tensor([0.7001])\n"," Train accuracy:  tensor([0.6999])\n"," Train accuracy:  tensor([0.7004])\n"," Train accuracy:  tensor([0.7007])\n"," Train accuracy:  tensor([0.7009])\n"," Train accuracy:  tensor([0.7011])\n"," Train accuracy:  tensor([0.7013])\n","Elapsed time:  922.5219156742096\n"," Train accuracy:  tensor([0.7057])\n"," Train accuracy:  tensor([0.7034])\n"," Train accuracy:  tensor([0.7037])\n"," Train accuracy:  tensor([0.7034])\n"," Train accuracy:  tensor([0.7027])\n"," Train accuracy:  tensor([0.7035])\n"," Train accuracy:  tensor([0.7039])\n"," Train accuracy:  tensor([0.7039])\n"," Train accuracy:  tensor([0.7037])\n"," Train accuracy:  tensor([0.7040])\n"," Train accuracy:  tensor([0.7040])\n"," Train accuracy:  tensor([0.7039])\n"," Train accuracy:  tensor([0.7041])\n"," Train accuracy:  tensor([0.7040])\n","Elapsed time:  889.2558073997498\n"," Train accuracy:  tensor([0.7065])\n"," Train accuracy:  tensor([0.7051])\n"," Train accuracy:  tensor([0.7063])\n"," Train accuracy:  tensor([0.7047])\n"," Train accuracy:  tensor([0.7056])\n"," Train accuracy:  tensor([0.7058])\n"," Train accuracy:  tensor([0.7054])\n"," Train accuracy:  tensor([0.7050])\n"," Train accuracy:  tensor([0.7051])\n"," Train accuracy:  tensor([0.7051])\n"," Train accuracy:  tensor([0.7053])\n"," Train accuracy:  tensor([0.7055])\n"]}]},{"cell_type":"code","metadata":{"id":"4b898225"},"source":["print(classification_report(np.array(test_labels).reshape(len(test_labels),1), predictions_4))"],"id":"4b898225","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c50Y1ObIh35B"},"source":["# Classification report without 'true' label\n","print(classification_report(np.array(test_labels).reshape(len(test_labels),1), predictions_4, labels = [1,2,3,4,5]))"],"id":"c50Y1ObIh35B","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtagSNrTh3yi"},"source":["# Confusion matrix\n","print(confusion_matrix(np.array(test_labels).reshape(len(test_labels),1), predictions_4))"],"id":"mtagSNrTh3yi","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_3yh-XIegD3a"},"id":"_3yh-XIegD3a","execution_count":null,"outputs":[]}]}